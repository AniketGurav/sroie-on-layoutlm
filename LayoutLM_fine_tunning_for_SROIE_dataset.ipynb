{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LayoutLM fine tunning for SROIE dataset.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNZan6OhxKPr+juS35J0+HZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruifcruz/sroie-on-layoutlm/blob/main/LayoutLM_fine_tunning_for_SROIE_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhsgXwhFoXaf"
      },
      "source": [
        "# Fine tune SROIE on LayoutLM\n",
        "This notebook is an effort to fine tune the LayoutLM model for the SROIE dataset. The model is presented in the paper \"[LayoutLM: Pre-training of Text and Layout for Document Image Understanding](https://arxiv.org/abs/1912.13318)\" by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei and Ming Zhou. \n",
        "\n",
        "- Git-hub repo [here](https://github.com/microsoft/unilm/tree/master/layoutlm).\n",
        "\n",
        "- Read about the SROIE competition and dataset [here](https://rrc.cvc.uab.es/?ch=13).\n",
        "\n",
        "- Inspiration from this Kaggle notebook [here](https://www.kaggle.com/jpmiller/layoutlm-starter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySxxGRALM1E-"
      },
      "source": [
        "##Notes:\n",
        "- The repo includes a pre processing script and fune tunning for the FUNSD dataset, but not for the SROIE dataset (though the paper includes computations on the SROIE dataset). So this notebook intends to fill that gap\n",
        "\n",
        "- I have used my google drive to manage the files. If you want to use it, just change the folder names (both the ones where you keep the SROIE files and also were you keep the LayoutLM files)\n",
        "\n",
        "- The best f1 results on the predicitons I got were between 93%~ 94.5%, which is a bit less than the value presented in the paper (~94%/95%). The differences may be explained by \n",
        "  - different parameters (I haven't done an exaustive grid search)\n",
        "  - different sampling\n",
        "  - different pre processing. This one is far from perfect, some labels and invoices are lost in the way. \n",
        "  - different OCR base. As I understood, the authors also did their own OCR, while I run from th one provided in the dataset\n",
        "  - I was having difficulties with the label \"company address\" so I have dropped it\n",
        "  - any other differences, as the paper doesn't explain this fine tunning in detail\n",
        "\n",
        "- Make sure you have GPU enabled on the notebook (Edit->Notebook settings)\n",
        "\n",
        "- Yes I know, the code is horrible and badly explained, sorry for that. Nevertheless, hope it helps somehow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgkoxJF8P7Gw"
      },
      "source": [
        "# 1. Pre-process dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEOrg6ePPzj9"
      },
      "source": [
        "# Imports  \n",
        "import os\n",
        "import pandas as pd\n",
        "import glob\n",
        "import json \n",
        "import ast\n",
        "import re\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSmwMiADoV8y",
        "outputId": "a1fb9e82-b311-4be4-f050-936749578e4f"
      },
      "source": [
        "# Connection to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ7VWGtnQZVB",
        "outputId": "655c59f2-b975-40ee-b5c3-54f9def74b7d"
      },
      "source": [
        "# Define path for the dataset files (you should previously download the dataset from the link given at the header of the notebook)\n",
        "# This is the folder with the files that contain the bounding boxes and the words\n",
        "spath_words = '/content/drive/My Drive/Msc/Tese/Datasets/SROIE2019/0325updated.task1train(626p)/'\n",
        "os.chdir(spath_words)\n",
        "# Create a dataframe to store and manage the invoices bounding boxes and words\n",
        "df_sentences = pd.DataFrame(columns=['filename', 'sentence'])\n",
        "\n",
        "# Loops over every file in the folder\n",
        "for file in glob.glob(\"*.txt\"):\n",
        "  try:\n",
        "    # Treat each invoice as a sentence and a row of the df\n",
        "    sfullpath = spath_words + file\n",
        "    df_file = pd.read_csv(sfullpath, header=None, names=['x0', 'y0', 'x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'words'])\n",
        "    if not df_file['words'].isnull().values.any():\n",
        "      sentence_list = [str(i) for i in df_file['words']]\n",
        "      bbox_list = []\n",
        "      for index, row in df_file.iterrows():\n",
        "        bbox_list.append([row['x0'],row['y0'],row['x2'],row['y2']])\n",
        "      new_row = {'filename':file, 'sentence':sentence_list, 'bboxes':bbox_list}\n",
        "      # Append row to the dataframe\n",
        "      df_sentences = df_sentences.append(new_row, ignore_index=True)\n",
        "  except Exception as e:\n",
        "    # There are a few problems, we will just ignore them and print the error associated with it\n",
        "    print(file + \" | \" + repr(e))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X51006619545.txt | ParserError('Error tokenizing data. C error: EOF inside string starting at row 78',)\n",
            "X51006619785.txt | ParserError('Error tokenizing data. C error: EOF inside string starting at row 77',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mysx1l8QZRN",
        "outputId": "b9ab285b-8b83-44e8-d634-82a300b777dd"
      },
      "source": [
        "# Define path for the dataset files (you should previously download the dataset from the link given at the header of the notebook)\n",
        "# This is the folder with the files that contain the values (company name, date, address and total)\n",
        "spath_labels = '/content/drive/My Drive/Msc/Tese/Datasets/SROIE2019/0325updated.task2train(626p)/'\n",
        "os.chdir(spath_labels)\n",
        "# Create a dataframe to store and manage the invoices tags\n",
        "df_labels = pd.DataFrame(columns=['filename', 'value_company', 'value_date', 'value_address', 'value_total'])\n",
        "\n",
        "for file in glob.glob(\"*.txt\"):\n",
        "  try:\n",
        "    with open(file, 'r') as fileread:\n",
        "      data = res = json.loads(fileread.read()) \n",
        "    new_row = {'filename':file, 'value_company':data['company'], 'value_date':data['date'], 'value_address':data['address'], 'value_total':data['total']}\n",
        "    # Append row to the dataframe\n",
        "    df_labels = df_labels.append(new_row, ignore_index=True)\n",
        "  except Exception as e:\n",
        "    print(file + \" | \" + repr(e))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X51005663280(1).txt | KeyError('address',)\n",
            "X51005663280.txt | KeyError('address',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBrnDgl1QZPr"
      },
      "source": [
        "# Now let's merge the two dataframes based on the filename\n",
        "df = pd.merge(df_sentences,df_labels,on='filename')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzOtABk5sa3o"
      },
      "source": [
        "# In case you want to store the df on drive (to avoid running the previous cells again and again), just uncomment this cell\n",
        "# os.chdir('/content/drive/My Drive/Msc/Tese/Datasets/SROIE2019/')\n",
        "# df.to_csv('df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4loa38UeswtT"
      },
      "source": [
        "# In case the df is stored on drive, just uncomment this cell\n",
        "# df = pd.read_csv('/content/drive/My Drive/Msc/Tese/Datasets/SROIE2019/df.csv')\n",
        "# df = df.drop(['Unnamed: 0'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMUshjyKQZMO"
      },
      "source": [
        "# Drop unecessary column and parse data (need to avoid some quotes inside the lists)\n",
        "df['sentence'] = df['sentence'].map(lambda a: ast.literal_eval(a))\n",
        "df['bboxes'] = df['bboxes'].map(lambda a: ast.literal_eval(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "d5adQ_5_QZIK",
        "outputId": "2218aec3-e356-4917-dce4-0f242ee79cff"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>sentence</th>\n",
              "      <th>bboxes</th>\n",
              "      <th>value_company</th>\n",
              "      <th>value_date</th>\n",
              "      <th>value_address</th>\n",
              "      <th>value_total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>X51005447852.txt</td>\n",
              "      <td>[99 SPEED MART S/B (519537-X), LOT P.T. 2811, ...</td>\n",
              "      <td>[[178, 341, 671, 378], [200, 389, 674, 431], [...</td>\n",
              "      <td>99 SPEED MART S/B</td>\n",
              "      <td>20-02-18</td>\n",
              "      <td>LOT P.T. 2811, JALAN ANGSA, TAMAN BERKELEY 411...</td>\n",
              "      <td>9.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>X51008114281.txt</td>\n",
              "      <td>[99 SPEED MART S/B (519537-X), LOP P.T. 2811, ...</td>\n",
              "      <td>[[153, 332, 648, 373], [176, 380, 650, 431], [...</td>\n",
              "      <td>99 SPEED MART S/B</td>\n",
              "      <td>04-06-18</td>\n",
              "      <td>LOT P.T. 2811, JALAN ANGSA, TAMAN BERKELEY 411...</td>\n",
              "      <td>23.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>X51006556852.txt</td>\n",
              "      <td>[GARDENIA BAKERIES (KL) SDN BHD (139386 X), LO...</td>\n",
              "      <td>[[36, 124, 591, 147], [172, 148, 450, 170], [1...</td>\n",
              "      <td>GARDENIA BAKERIES (KL) SDN BHD</td>\n",
              "      <td>11/09/2017</td>\n",
              "      <td>LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SE...</td>\n",
              "      <td>65.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>X51007339642(1).txt</td>\n",
              "      <td>[AIK HUAT HARDWARE, ENTERPRISE (SETIA, ALAM) S...</td>\n",
              "      <td>[[73, 194, 502, 225], [77, 221, 503, 250], [12...</td>\n",
              "      <td>AIK HUAT HARDWARE ENTERPRISE (SETIA ALAM) SDN BHD</td>\n",
              "      <td>28/09/2017</td>\n",
              "      <td>NO. 17-G, JALAN SETIA INDAH (X) U13/X, SETIA A...</td>\n",
              "      <td>14.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>X51005806678(1).txt</td>\n",
              "      <td>[KAISON FURNISHING SDN BHD, L4-17 (B), UP2-01,...</td>\n",
              "      <td>[[333, 214, 698, 252], [378, 279, 652, 318], [...</td>\n",
              "      <td>KAISON FURNISHING SDN BHD</td>\n",
              "      <td>29-01-18</td>\n",
              "      <td>L4-17 (B), LEVEL 4, UP2-01, MELAWATI MALL, 355...</td>\n",
              "      <td>7838.80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              filename  ... value_total\n",
              "0     X51005447852.txt  ...        9.90\n",
              "1     X51008114281.txt  ...       23.40\n",
              "2     X51006556852.txt  ...       65.50\n",
              "3  X51007339642(1).txt  ...       14.00\n",
              "4  X51005806678(1).txt  ...     7838.80\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL2puOnnQZFA"
      },
      "source": [
        "# Define some auxiliary functions\n",
        "def a_in_x(A, X):\n",
        "  '''\n",
        "  Returns list with indexes of elements of list X which contain A\n",
        "  '''\n",
        "  l = []\n",
        "  for i in range(len(X) - len(A) + 1):\n",
        "    if str(A[0]) in str(X[i:i+len(A)][0]): \n",
        "      l.append(i)\n",
        "  return l\n",
        "\n",
        "def flat_list_one_level(l):\n",
        "  '''\n",
        "  Flattens list\n",
        "  Doesn't include second level list of lists, only first level\n",
        "  '''\n",
        "  flat_list = []\n",
        "  for sublist in l:\n",
        "    if type(sublist) is list:\n",
        "      for item in sublist:\n",
        "          flat_list.append(item)\n",
        "    else:\n",
        "      flat_list.append(sublist)\n",
        "  return flat_list\n",
        "\n",
        "def flat_list_one_level_list_of_lists(l):\n",
        "  '''\n",
        "  Flattens list\n",
        "  Flattens only the first element of the sub-list\n",
        "  '''\n",
        "  flat_list = []\n",
        "  for sublist in l:\n",
        "    if type(sublist) is list and len(sublist) > 0 and type(sublist[0]) is list:\n",
        "      for item in sublist:\n",
        "        flat_list.append(item)\n",
        "    else:\n",
        "      flat_list.append(sublist)\n",
        "  return flat_list\n",
        "    \n",
        "def intersperse(lst, item):\n",
        "  '''\n",
        "  Places an item between elements of a list\n",
        "  '''\n",
        "  result = [item] * (len(lst) * 2 - 1)\n",
        "  result[0::2] = lst\n",
        "  return result\n",
        "\n",
        "def split_box(box, n_splits):\n",
        "  '''\n",
        "  Splits a bbox [x0,y0,x1,y1] by its coordinates into n_splits bboxes of equal size\n",
        "  '''\n",
        "  boxs_splitted = []\n",
        "  x0 = box[0]\n",
        "  y0 = box[1]\n",
        "  x1 = box[2]\n",
        "  y1 = box[3]\n",
        "  width = x1 - x0\n",
        "  for i_split in range(0, n_splits):\n",
        "    boxs_splitted.append([x0 + i_split * int(width/n_splits), y0, x0 + (i_split + 1) * int(width/n_splits), y1])\n",
        "  return boxs_splitted\n",
        "\n",
        "def split_box_weighted(box, l_splits):\n",
        "  '''\n",
        "  Splits a bbox [x0,y0,x1,y1] by its coordinates into len(l_splits)\n",
        "  The size of each bbox is proportional to the weight present in l_splits\n",
        "  '''\n",
        "  boxs_splitted = []\n",
        "  x0 = box[0]\n",
        "  y0 = box[1]\n",
        "  x1 = box[2]\n",
        "  y1 = box[3]\n",
        "  width = x1 - x0\n",
        "  sum_splits = sum(l_splits)\n",
        "  for i_split in l_splits:\n",
        "    split_fraction = i_split/sum_splits\n",
        "    x1f = x0 + int(width * split_fraction)\n",
        "    boxs_splitted.append([x0, y0, x1f, y1])\n",
        "    x0 = x1f\n",
        "  return boxs_splitted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyMuxO6CQZB8"
      },
      "source": [
        "# Define function to set the labels to the words\n",
        "def define_labels(pos, sent, labels, bbox, class_value, classification, label_other = 'O'):\n",
        "  # Pos is a list whith the position of the words associated with this label\n",
        "  # So this loops each group of words which has some relation to the label\n",
        "  for i_pos in pos:\n",
        "    if sent[i_pos] == class_value:\n",
        "      # If the group of words is equal to the class value, then this group of words is attributted the label\n",
        "      labels[i_pos] = classification\n",
        "    else:\n",
        "      # The value is contained within the group of words, so we have to split the group (ex: [... , \"Date: 01/01/2020\", ...] -> [..., [\"Date: \", \"01/01/2020\"], ...])\n",
        "      # We start by replacing the group of words by a splitted list \n",
        "      sent[i_pos] = intersperse(sent[i_pos].split(str(class_value)), str(class_value))\n",
        "      # This split leaves a white space element at the initial or final position, so we have to remove it\n",
        "      if sent[i_pos][0].isspace() or len(sent[i_pos][0])==0: sent[i_pos] = sent[i_pos][1:]\n",
        "      if sent[i_pos][-1].isspace() or len(sent[i_pos][-1])==0: sent[i_pos] = sent[i_pos][0:-1]\n",
        "      # Now we may associate the labels with the correct group of words (ex: [... , \"Date: 01/01/2020\", ...] -> [..., [\"Date: \", \"01/01/2020\"], ...], the labels would be [..., [\"O\", \"B-DATE\"], ...])\n",
        "      labels[i_pos] = [classification if s == class_value else label_other for s in sent[i_pos]]\n",
        "      # The bounding boxes should also be splitted\n",
        "      # Here we do it proportionally to the number of chars of the words\n",
        "      bbox[i_pos] = split_box_weighted(bbox[i_pos], [len(i) for i in sent[i_pos]])\n",
        "\n",
        "  # The obtained lists have now some second level lists, so we have to flatten\n",
        "  sent = flat_list_one_level(sent)\n",
        "  labels = flat_list_one_level(labels)\n",
        "  bbox = flat_list_one_level_list_of_lists(bbox)\n",
        "  return sent, labels, bbox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1aaCv6uQY93"
      },
      "source": [
        "# Finally the loop to create lists with the sentences and their corresponding labels and bboxes\n",
        "sentences_list = []\n",
        "labels_list = []\n",
        "bbox_list = []\n",
        "class_other = 'O'\n",
        "for index, row in df.iterrows():\n",
        "  labels = [class_other] * len(row['sentence'])\n",
        "  sent = row['sentence'].copy()\n",
        "  bbox = row['bboxes'].copy()\n",
        "  \n",
        "  # Define labels for date\n",
        "  class_value = row['value_date']\n",
        "  classification = 'B-DATE'\n",
        "  pos = a_in_x([class_value], sent)\n",
        "  if len(pos) > 0:\n",
        "    sent, labels, bbox = define_labels(pos, sent, labels, bbox, class_value, classification)\n",
        "  \n",
        "  # Define labels for total value\n",
        "  class_value = row['value_total']\n",
        "  classification = 'B-TOTAL'\n",
        "  pos = a_in_x([class_value], sent)\n",
        "  if len(pos) > 0:\n",
        "    sent, labels, bbox = define_labels(pos, sent, labels, bbox, class_value, classification)  \n",
        "\n",
        "  # Define labels for company name\n",
        "  class_value = row['value_company']\n",
        "  classification = 'B-COMPANY'\n",
        "  pos = a_in_x([class_value], sent)\n",
        "  if len(pos) > 0:\n",
        "    sent, labels, bbox = define_labels(pos, sent, labels, bbox, class_value, classification)\n",
        "\n",
        "  # Define labels for address \n",
        "  # class_value = row['value_address']\n",
        "  # classification = 'B-ADDRESS'\n",
        "  # pos = a_in_x([class_value], sent)\n",
        "  # if len(pos) > 0:\n",
        "  #   sent, labels, bbox = define_labels(pos, sent, labels, bbox, class_value, classification)\n",
        "\n",
        "  # Appends the group of words, labels and bboxes to lists\n",
        "  sentences_list.append(sent.copy())\n",
        "  labels_list.append(labels.copy())\n",
        "  bbox_list.append(bbox.copy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJyX76wIjKMz"
      },
      "source": [
        "At this point we have lists in which the elements are also lists (groups of words)\n",
        "\n",
        "In order to discretize the problem, we should split the groups of words into single words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utJcFc73exM4"
      },
      "source": [
        "def break_sentences(sl, bl, ll):\n",
        "  sentences_list_temp = []\n",
        "  bbox_list_temp = []\n",
        "  labels_list_temp = []\n",
        "  for sents, labels, boxs in zip(sl, bl, ll):\n",
        "    sentences_list3 = []\n",
        "    bbox_list3 = []\n",
        "    labels_list3 = []\n",
        "    for sent, label, box in zip(sents, labels, boxs):\n",
        "      word_tokens = sent.split(\" \")\n",
        "      # Strip white spaces\n",
        "      word_tokens = [w for w in word_tokens if (w != \"\" and w != \" \")] \n",
        "      sentences_list3.extend(word_tokens)\n",
        "      splitted_boxes = split_box_weighted(box, [len(i) for i in word_tokens])\n",
        "      bbox_list3.extend(splitted_boxes)\n",
        "      # BO\n",
        "      labels_list3.extend([label] * len(word_tokens))\n",
        "      # BIO\n",
        "      #labels_list3.extend([label] + [label.replace('B-','I-')] * (len(word_tokens) - 1))\n",
        "    sentences_list_temp.append(sentences_list3)\n",
        "    bbox_list_temp.append(bbox_list3)\n",
        "    labels_list_temp.append(labels_list3)\n",
        "  return sentences_list_temp, bbox_list_temp, labels_list_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IwIpq3aexH2"
      },
      "source": [
        "sentences_list, bbox_list, labels_list = break_sentences(sentences_list, labels_list, bbox_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV9kuYURtNji",
        "outputId": "faf40ce0-8981-4b5b-e5c4-0e5aa199f004"
      },
      "source": [
        "# Check the first invoice data\n",
        "for s, l, b in zip(sentences_list[0],labels_list[0],bbox_list[0]):\n",
        "  print(\"{}\\t\\t{}\\t\\t{}\".format(s,l,b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99\t\tB-COMPANY\t\t[178, 341, 220, 378]\n",
            "SPEED\t\tB-COMPANY\t\t[220, 341, 326, 378]\n",
            "MART\t\tB-COMPANY\t\t[326, 341, 411, 378]\n",
            "S/B\t\tB-COMPANY\t\t[411, 341, 475, 378]\n",
            "(519537-X)\t\tO\t\t[477, 341, 670, 378]\n",
            "LOT\t\tO\t\t[200, 389, 329, 431]\n",
            "P.T.\t\tO\t\t[329, 389, 501, 431]\n",
            "2811\t\tO\t\t[501, 389, 673, 431]\n",
            "TAMAN\t\tO\t\t[304, 438, 399, 474]\n",
            "BERKELEY\t\tO\t\t[399, 438, 551, 474]\n",
            "41150\t\tO\t\t[256, 489, 441, 530]\n",
            "KLANG\t\tO\t\t[441, 489, 626, 530]\n",
            "1249-TMN\t\tO\t\t[233, 538, 391, 575]\n",
            "PANDAN\t\tO\t\t[391, 538, 509, 575]\n",
            "CAHAYA\t\tO\t\t[509, 538, 627, 575]\n",
            "GST\t\tO\t\t[220, 590, 283, 625]\n",
            "ID.\t\tO\t\t[283, 590, 346, 625]\n",
            "NO\t\tO\t\t[346, 590, 388, 625]\n",
            ":\t\tO\t\t[388, 590, 409, 625]\n",
            "000181747712\t\tO\t\t[409, 590, 662, 625]\n",
            "INVOICE\t\tO\t\t[198, 689, 336, 728]\n",
            "NO\t\tO\t\t[336, 689, 375, 728]\n",
            ":\t\tO\t\t[375, 689, 394, 728]\n",
            "18314/102/T0422\t\tO\t\t[394, 689, 691, 728]\n",
            "06:20PM\t\tO\t\t[99, 787, 221, 823]\n",
            "568008\t\tO\t\t[399, 789, 505, 820]\n",
            "20-02-18\t\tB-DATE\t\t[660, 786, 805, 823]\n",
            "8991\t\tO\t\t[97, 885, 179, 922]\n",
            "NUTRI\t\tO\t\t[179, 885, 282, 922]\n",
            "PLUS\t\tO\t\t[282, 885, 364, 922]\n",
            "TELUR\t\tO\t\t[364, 885, 467, 922]\n",
            "SEGAR\t\tO\t\t[467, 885, 570, 922]\n",
            "RM\t\tO\t\t[663, 886, 699, 921]\n",
            "9.90\t\tB-TOTAL\t\t[699, 886, 771, 921]\n",
            "Z\t\tO\t\t[771, 886, 807, 921]\n",
            "TOTAL\t\tO\t\t[99, 983, 201, 1022]\n",
            "SALES\t\tO\t\t[201, 983, 303, 1022]\n",
            "(INCLUSIVE\t\tO\t\t[303, 983, 507, 1022]\n",
            "GST)\t\tO\t\t[507, 983, 588, 1022]\n",
            "RM\t\tO\t\t[588, 983, 628, 1022]\n",
            "9.90\t\tB-TOTAL\t\t[700, 987, 772, 1021]\n",
            "CASH\t\tO\t\t[500, 1034, 584, 1071]\n",
            "RM\t\tO\t\t[584, 1034, 626, 1071]\n",
            "10.00\t\tO\t\t[681, 1036, 767, 1071]\n",
            "CHANGE\t\tO\t\t[468, 1085, 590, 1121]\n",
            "RM\t\tO\t\t[590, 1085, 630, 1121]\n",
            ".10\t\tO\t\t[715, 1088, 771, 1120]\n",
            "GST\t\tO\t\t[96, 1182, 154, 1227]\n",
            "SUMMARY\t\tO\t\t[154, 1182, 291, 1227]\n",
            "AMOUNT(RM)\t\tO\t\t[382, 1183, 554, 1220]\n",
            "TAX(RM)\t\tO\t\t[665, 1184, 785, 1220]\n",
            "Z\t\tO\t\t[91, 1234, 119, 1268]\n",
            "=\t\tO\t\t[119, 1234, 147, 1268]\n",
            "0%\t\tO\t\t[147, 1234, 203, 1268]\n",
            "9.90\t\tB-TOTAL\t\t[483, 1235, 557, 1269]\n",
            ".00\t\tO\t\t[731, 1234, 785, 1268]\n",
            "THANK\t\tO\t\t[182, 1382, 285, 1427]\n",
            "YOU.\t\tO\t\t[285, 1382, 368, 1427]\n",
            "PLEASE\t\tO\t\t[368, 1382, 492, 1427]\n",
            "COME\t\tO\t\t[492, 1382, 575, 1427]\n",
            "AGAIN\t\tO\t\t[575, 1382, 678, 1427]\n",
            "KEEP\t\tO\t\t[95, 1431, 175, 1472]\n",
            "THE\t\tO\t\t[175, 1431, 235, 1472]\n",
            "INVOICE\t\tO\t\t[235, 1431, 376, 1472]\n",
            "FOR\t\tO\t\t[376, 1431, 436, 1472]\n",
            "APPLICABLE\t\tO\t\t[436, 1431, 638, 1472]\n",
            "RETURNS\t\tO\t\t[638, 1431, 779, 1472]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCZM2Ne_jQ41"
      },
      "source": [
        "Now everything is ready to write the files in the correct format (accepted by the layoutLM process)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G-esUmGexBk"
      },
      "source": [
        "def bbox_string(box, width, length):\n",
        "    return (\n",
        "        str(int(1000 * (box[0] / width)))\n",
        "        + \" \"\n",
        "        + str(int(1000 * (box[1] / length)))\n",
        "        + \" \"\n",
        "        + str(int(1000 * (box[2] / width)))\n",
        "        + \" \"\n",
        "        + str(int(1000 * (box[3] / length)))\n",
        "    )\n",
        "\n",
        "def actual_bbox_string(box, width, length):\n",
        "    return (\n",
        "        str(box[0])\n",
        "        + \" \"\n",
        "        + str(box[1])\n",
        "        + \" \"\n",
        "        + str(box[2])\n",
        "        + \" \"\n",
        "        + str(box[3])\n",
        "        + \"\\t\"\n",
        "        + str(width)\n",
        "        + \" \"\n",
        "        + str(length)\n",
        "    )\n",
        "\n",
        "def size(bboxes):\n",
        "  max_width = 0\n",
        "  max_height = 0\n",
        "  min_x0 = 10e8\n",
        "  min_y0 = 10e8\n",
        "  for box in bboxes:\n",
        "    if box[0] < min_x0: min_x0 = box[0]\n",
        "    if box[1] < min_y0: min_y0 = box[1]\n",
        "    if box[2] > max_width: max_width = box[2]\n",
        "    if box[3] > max_height: max_height = box[3]\n",
        "  max_width += min_x0\n",
        "  max_height += min_y0\n",
        "  return max_height, max_width\n",
        "\n",
        "def get_unique(some_array, seen=None):\n",
        "    if seen is None:\n",
        "        seen = set()\n",
        "    for i in some_array:\n",
        "        if isinstance(i, list):\n",
        "            seen.union(get_unique(i, seen))\n",
        "        else:\n",
        "            seen.add(i)\n",
        "    return list(seen)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uUKRS6uew_l"
      },
      "source": [
        "def write_files(output_dir, data_split, sentences_list, labels_list, bbox_list, split_indexes):\n",
        "  with open(\n",
        "      os.path.join(output_dir, data_split + \".txt\"),\n",
        "      \"w\",\n",
        "      encoding=\"utf8\",\n",
        "  ) as fw, open(\n",
        "      os.path.join(output_dir, data_split + \"_box.txt\"),\n",
        "      \"w\",\n",
        "      encoding=\"utf8\",\n",
        "  ) as fbw, open(\n",
        "      os.path.join(output_dir, data_split + \"_image.txt\"),\n",
        "      \"w\",\n",
        "      encoding=\"utf8\",\n",
        "  ) as fiw:\n",
        "      for index in split_indexes:\n",
        "          sent = sentences_list[index]\n",
        "          lab = labels_list[index]\n",
        "          boxes = bbox_list[index]\n",
        "          length, width = size(boxes)\n",
        "\n",
        "          for words, label, box in zip(sent, lab, boxes):\n",
        "              fw.write(\"{}\\t{}\\n\".format(words, label))\n",
        "              fbw.write(\"{}\\t{}\\n\".format(words, bbox_string(box, width, length)))\n",
        "              fiw.write(\"{}\\t{}\\t{}\\n\".format(words, actual_bbox_string(box, width, length), \"filename.jpg\"))\n",
        "          fw.write(\"\\n\")\n",
        "          fbw.write(\"\\n\")\n",
        "          fiw.write(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPik5XFdew6e"
      },
      "source": [
        "# First we split into train and test set\n",
        "split_indexes = [*range(len(sentences_list))]\n",
        "random.Random(4).shuffle(split_indexes)\n",
        "cut = int(len(sentences_list) * 0.8)\n",
        "split_indexes_train = split_indexes[:cut]\n",
        "split_indexes_test = split_indexes[cut:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG_FtTFQew23"
      },
      "source": [
        "write_files('/content/drive/My Drive/Msc/Tese/Datasets/SROIE2019/', 'train', sentences_list, labels_list, bbox_list, split_indexes_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiEgjjPSm83z"
      },
      "source": [
        "write_files('/content/drive/My Drive/Msc/Tese/Datasets/SROIE2019/', 'test', sentences_list, labels_list, bbox_list, split_indexes_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX_A7a_h1Bk2"
      },
      "source": [
        "# Finally we write the labels.txt file\r\n",
        "tag_values = get_unique(labels_list)\r\n",
        "with open(\r\n",
        "      os.path.join('/content/drive/My Drive/Msc/Tese/Datasets/SROIE2019/', \"labels.txt\"),\r\n",
        "      \"w\",\r\n",
        "      encoding=\"utf8\",\r\n",
        "  ) as lb:\r\n",
        "      for val in tag_values:\r\n",
        "        lb.write(\"{}\\n\".format(val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKI4qpxUP-dk"
      },
      "source": [
        "# 2. Fine tune LayoutLM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaCCceLFups_"
      },
      "source": [
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLhS7g4gQEKz",
        "outputId": "28779a3a-eb80-4e22-ce7d-a013fcf65753"
      },
      "source": [
        "%%bash\n",
        "git clone https://github.com/microsoft/unilm.git\n",
        "cd unilm/layoutlm\n",
        "pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/unilm/layoutlm\n",
            "Requirement already satisfied: transformers==2.9.0 in /usr/local/lib/python3.6/dist-packages (from layoutlm==0.0) (2.9.0)\n",
            "Requirement already satisfied: tensorboardX==2.0 in /usr/local/lib/python3.6/dist-packages (from layoutlm==0.0) (2.0)\n",
            "Requirement already satisfied: lxml==4.5.1 in /usr/local/lib/python3.6/dist-packages (from layoutlm==0.0) (4.5.1)\n",
            "Requirement already satisfied: seqeval==0.0.12 in /usr/local/lib/python3.6/dist-packages (from layoutlm==0.0) (0.0.12)\n",
            "Requirement already satisfied: Pillow==7.1.2 in /usr/local/lib/python3.6/dist-packages (from layoutlm==0.0) (7.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0->layoutlm==0.0) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0->layoutlm==0.0) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0->layoutlm==0.0) (0.0.43)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0->layoutlm==0.0) (0.1.94)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0->layoutlm==0.0) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0->layoutlm==0.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0->layoutlm==0.0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0->layoutlm==0.0) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0->layoutlm==0.0) (0.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX==2.0->layoutlm==0.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==2.0->layoutlm==0.0) (3.12.4)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval==0.0.12->layoutlm==0.0) (2.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.0->layoutlm==0.0) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.0->layoutlm==0.0) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0->layoutlm==0.0) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0->layoutlm==0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0->layoutlm==0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0->layoutlm==0.0) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX==2.0->layoutlm==0.0) (50.3.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval==0.0.12->layoutlm==0.0) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval==0.0.12->layoutlm==0.0) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval==0.0.12->layoutlm==0.0) (3.13)\n",
            "Building wheels for collected packages: layoutlm\n",
            "  Building wheel for layoutlm (setup.py): started\n",
            "  Building wheel for layoutlm (setup.py): finished with status 'done'\n",
            "  Created wheel for layoutlm: filename=layoutlm-0.0-cp36-none-any.whl size=11484 sha256=4509f71db801ad23d552705ca0a200c660112c560c17fd0fb73631d2d847009d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-v49lumeh/wheels/e8/9a/90/87de19930fb582e6176ea7912010f101efa37def32b8ced268\n",
            "Successfully built layoutlm\n",
            "Installing collected packages: layoutlm\n",
            "  Found existing installation: layoutlm 0.0\n",
            "    Uninstalling layoutlm-0.0:\n",
            "      Successfully uninstalled layoutlm-0.0\n",
            "Successfully installed layoutlm-0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'unilm'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWOvS1fgoja9"
      },
      "source": [
        "os.chdir('/content/unilm/layoutlm/examples/seq_labeling')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwaathndok3P",
        "outputId": "a9bc0c48-8f2d-4b58-b3c6-49bb71853ca7"
      },
      "source": [
        "# Move the previously created files\n",
        "%%bash\n",
        "mkdir data\n",
        "cp '/content/drive/My Drive/Msc/Tese/Datasets/SROIE2019/train.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/My Drive/Msc/Tese/Datasets/SROIE2019/train_box.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/My Drive/Msc/Tese/Datasets/SROIE2019/train_image.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/My Drive/Msc/Tese/Datasets/SROIE2019/test.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/My Drive/Msc/Tese/Datasets/SROIE2019/test_box.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/My Drive/Msc/Tese/Datasets/SROIE2019/test_image.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/My Drive/Msc/Tese/Datasets/SROIE2019/labels.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "# Try to remove cached files (this is optional and only important if we make changes on the input files)\n",
        "rm '/content/unilm/layoutlm/examples/seq_labeling/data/cached_train_layoutlm-base-uncased_512'\n",
        "rm '/content/unilm/layoutlm/examples/seq_labeling/data/cached_test_layoutlm-base-uncased_512'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/unilm/layoutlm/examples/seq_labeling/data/cached_train_layoutlm-base-uncased_512': No such file or directory\n",
            "rm: cannot remove '/content/unilm/layoutlm/examples/seq_labeling/data/cached_test_layoutlm-base-uncased_512': No such file or directory\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsmESs_9okzf",
        "outputId": "6b1d6c44-a187-413d-e6f6-6a2851a216f7"
      },
      "source": [
        "%%bash\n",
        "ls /content/unilm/layoutlm/examples/seq_labeling/data/\n",
        "cat /content/unilm/layoutlm/examples/seq_labeling/data/labels.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels.txt\n",
            "test_box.txt\n",
            "test_image.txt\n",
            "test.txt\n",
            "train_box.txt\n",
            "train_image.txt\n",
            "train.txt\n",
            "O\n",
            "B-DATE\n",
            "B-COMPANY\n",
            "B-TOTAL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys6E6dNyokwi",
        "outputId": "ff879bf9-3315-4c41-bb19-6a1d790f545a"
      },
      "source": [
        "# Check model parameters\n",
        "cat \"/content/drive/My Drive/Msc/Tese/Modelos/layoutlm-base-uncased/config.json\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_2d_position_embeddings\": 1024,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6OahJzprO4-"
      },
      "source": [
        "# Want to change any model parameter? For example here I just replace the number of attention heads from 12 to 8 (the results are much better)\n",
        "%%bash\n",
        "sed -i 's/\"num_attention_heads\": 12,/\"num_attention_heads\": 8,/' \"/content/drive/My Drive/Msc/Tese/Modelos/layoutlm-base-uncased/config.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgkLXCd7okvR",
        "outputId": "219a721a-de0e-4048-f61c-486f12317627"
      },
      "source": [
        "# Train the model\n",
        "! CUDA_LAUNCH_BLOCKING=1 python run_seq_labeling.py  --data_dir data \\\n",
        "                            --model_type layoutlm \\\n",
        "                            --model_name_or_path '/content/drive/My Drive/Msc/Tese/Modelos/layoutlm-base-uncased' \\\n",
        "                            --do_lower_case \\\n",
        "                            --max_seq_length 512 \\\n",
        "                            --do_train \\\n",
        "                            --num_train_epochs 5.0 \\\n",
        "                            --logging_steps 10 \\\n",
        "                            --save_steps -1 \\\n",
        "                            --output_dir output \\\n",
        "                            --overwrite_output_dir \\\n",
        "                            --labels data/labels.txt \\\n",
        "                            --per_gpu_train_batch_size 8 \\\n",
        "                            --per_gpu_eval_batch_size 8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-25 00:12:21.493624: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Epoch:   0% 0/5 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/71 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   1% 1/71 [00:00<01:01,  1.13it/s]\u001b[A\n",
            "Iteration:   3% 2/71 [00:01<00:58,  1.18it/s]\u001b[A\n",
            "Iteration:   4% 3/71 [00:02<00:56,  1.21it/s]\u001b[A\n",
            "Iteration:   6% 4/71 [00:03<00:54,  1.24it/s]\u001b[A\n",
            "Iteration:   7% 5/71 [00:03<00:52,  1.26it/s]\u001b[A\n",
            "Iteration:   8% 6/71 [00:04<00:50,  1.28it/s]\u001b[A\n",
            "Iteration:  10% 7/71 [00:05<00:49,  1.28it/s]\u001b[A\n",
            "Iteration:  11% 8/71 [00:06<00:48,  1.30it/s]\u001b[A\n",
            "Iteration:  13% 9/71 [00:06<00:47,  1.30it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "\n",
            "Iteration:  14% 10/71 [00:07<00:46,  1.31it/s]\u001b[A\n",
            "Iteration:  15% 11/71 [00:08<00:45,  1.31it/s]\u001b[A\n",
            "Iteration:  17% 12/71 [00:09<00:44,  1.32it/s]\u001b[A\n",
            "Iteration:  18% 13/71 [00:10<00:43,  1.32it/s]\u001b[A\n",
            "Iteration:  20% 14/71 [00:10<00:43,  1.32it/s]\u001b[A\n",
            "Iteration:  21% 15/71 [00:11<00:42,  1.32it/s]\u001b[A\n",
            "Iteration:  23% 16/71 [00:12<00:41,  1.32it/s]\u001b[A\n",
            "Iteration:  24% 17/71 [00:13<00:40,  1.32it/s]\u001b[A\n",
            "Iteration:  25% 18/71 [00:13<00:40,  1.32it/s]\u001b[A\n",
            "Iteration:  27% 19/71 [00:14<00:39,  1.32it/s]\u001b[A\n",
            "Iteration:  28% 20/71 [00:15<00:38,  1.32it/s]\u001b[A\n",
            "Iteration:  30% 21/71 [00:16<00:38,  1.32it/s]\u001b[A\n",
            "Iteration:  31% 22/71 [00:16<00:37,  1.32it/s]\u001b[A\n",
            "Iteration:  32% 23/71 [00:17<00:36,  1.31it/s]\u001b[A\n",
            "Iteration:  34% 24/71 [00:18<00:35,  1.31it/s]\u001b[A\n",
            "Iteration:  35% 25/71 [00:19<00:35,  1.31it/s]\u001b[A\n",
            "Iteration:  37% 26/71 [00:19<00:34,  1.30it/s]\u001b[A\n",
            "Iteration:  38% 27/71 [00:20<00:33,  1.30it/s]\u001b[A\n",
            "Iteration:  39% 28/71 [00:21<00:32,  1.31it/s]\u001b[A\n",
            "Iteration:  41% 29/71 [00:22<00:32,  1.31it/s]\u001b[A\n",
            "Iteration:  42% 30/71 [00:22<00:31,  1.30it/s]\u001b[A\n",
            "Iteration:  44% 31/71 [00:23<00:30,  1.30it/s]\u001b[A\n",
            "Iteration:  45% 32/71 [00:24<00:29,  1.30it/s]\u001b[A\n",
            "Iteration:  46% 33/71 [00:25<00:29,  1.31it/s]\u001b[A\n",
            "Iteration:  48% 34/71 [00:26<00:28,  1.31it/s]\u001b[A\n",
            "Iteration:  49% 35/71 [00:26<00:27,  1.30it/s]\u001b[A\n",
            "Iteration:  51% 36/71 [00:27<00:27,  1.29it/s]\u001b[A\n",
            "Iteration:  52% 37/71 [00:28<00:26,  1.29it/s]\u001b[A\n",
            "Iteration:  54% 38/71 [00:29<00:25,  1.29it/s]\u001b[A\n",
            "Iteration:  55% 39/71 [00:29<00:24,  1.29it/s]\u001b[A\n",
            "Iteration:  56% 40/71 [00:30<00:23,  1.29it/s]\u001b[A\n",
            "Iteration:  58% 41/71 [00:31<00:23,  1.30it/s]\u001b[A\n",
            "Iteration:  59% 42/71 [00:32<00:22,  1.30it/s]\u001b[A\n",
            "Iteration:  61% 43/71 [00:33<00:21,  1.30it/s]\u001b[A\n",
            "Iteration:  62% 44/71 [00:33<00:20,  1.29it/s]\u001b[A\n",
            "Iteration:  63% 45/71 [00:34<00:20,  1.29it/s]\u001b[A\n",
            "Iteration:  65% 46/71 [00:35<00:19,  1.29it/s]\u001b[A\n",
            "Iteration:  66% 47/71 [00:36<00:18,  1.30it/s]\u001b[A\n",
            "Iteration:  68% 48/71 [00:36<00:17,  1.30it/s]\u001b[A\n",
            "Iteration:  69% 49/71 [00:37<00:16,  1.30it/s]\u001b[A\n",
            "Iteration:  70% 50/71 [00:38<00:16,  1.30it/s]\u001b[A\n",
            "Iteration:  72% 51/71 [00:39<00:15,  1.30it/s]\u001b[A\n",
            "Iteration:  73% 52/71 [00:39<00:14,  1.30it/s]\u001b[A\n",
            "Iteration:  75% 53/71 [00:40<00:13,  1.29it/s]\u001b[A\n",
            "Iteration:  76% 54/71 [00:41<00:13,  1.29it/s]\u001b[A\n",
            "Iteration:  77% 55/71 [00:42<00:12,  1.29it/s]\u001b[A\n",
            "Iteration:  79% 56/71 [00:43<00:11,  1.29it/s]\u001b[A\n",
            "Iteration:  80% 57/71 [00:43<00:10,  1.28it/s]\u001b[A\n",
            "Iteration:  82% 58/71 [00:44<00:10,  1.28it/s]\u001b[A\n",
            "Iteration:  83% 59/71 [00:45<00:09,  1.28it/s]\u001b[A\n",
            "Iteration:  85% 60/71 [00:46<00:08,  1.29it/s]\u001b[A\n",
            "Iteration:  86% 61/71 [00:46<00:07,  1.29it/s]\u001b[A\n",
            "Iteration:  87% 62/71 [00:47<00:06,  1.29it/s]\u001b[A\n",
            "Iteration:  89% 63/71 [00:48<00:06,  1.29it/s]\u001b[A\n",
            "Iteration:  90% 64/71 [00:49<00:05,  1.29it/s]\u001b[A\n",
            "Iteration:  92% 65/71 [00:50<00:04,  1.29it/s]\u001b[A\n",
            "Iteration:  93% 66/71 [00:50<00:03,  1.29it/s]\u001b[A\n",
            "Iteration:  94% 67/71 [00:51<00:03,  1.30it/s]\u001b[A\n",
            "Iteration:  96% 68/71 [00:52<00:02,  1.29it/s]\u001b[A\n",
            "Iteration:  97% 69/71 [00:53<00:01,  1.29it/s]\u001b[A\n",
            "Iteration:  99% 70/71 [00:53<00:00,  1.29it/s]\u001b[A\n",
            "Iteration: 100% 71/71 [00:54<00:00,  1.30it/s]\n",
            "Epoch:  20% 1/5 [00:54<03:38, 54.69s/it]\n",
            "Iteration:   0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/71 [00:00<00:54,  1.29it/s]\u001b[A\n",
            "Iteration:   3% 2/71 [00:01<00:53,  1.29it/s]\u001b[A\n",
            "Iteration:   4% 3/71 [00:02<00:52,  1.29it/s]\u001b[A\n",
            "Iteration:   6% 4/71 [00:03<00:52,  1.29it/s]\u001b[A\n",
            "Iteration:   7% 5/71 [00:03<00:51,  1.29it/s]\u001b[A\n",
            "Iteration:   8% 6/71 [00:04<00:50,  1.29it/s]\u001b[A\n",
            "Iteration:  10% 7/71 [00:05<00:49,  1.28it/s]\u001b[A\n",
            "Iteration:  11% 8/71 [00:06<00:49,  1.28it/s]\u001b[A\n",
            "Iteration:  13% 9/71 [00:07<00:48,  1.27it/s]\u001b[A\n",
            "Iteration:  14% 10/71 [00:07<00:47,  1.27it/s]\u001b[A\n",
            "Iteration:  15% 11/71 [00:08<00:47,  1.28it/s]\u001b[A\n",
            "Iteration:  17% 12/71 [00:09<00:46,  1.27it/s]\u001b[A\n",
            "Iteration:  18% 13/71 [00:10<00:45,  1.28it/s]\u001b[A\n",
            "Iteration:  20% 14/71 [00:10<00:44,  1.28it/s]\u001b[A\n",
            "Iteration:  21% 15/71 [00:11<00:43,  1.28it/s]\u001b[A\n",
            "Iteration:  23% 16/71 [00:12<00:43,  1.28it/s]\u001b[A\n",
            "Iteration:  24% 17/71 [00:13<00:42,  1.28it/s]\u001b[A\n",
            "Iteration:  25% 18/71 [00:14<00:41,  1.28it/s]\u001b[A\n",
            "Iteration:  27% 19/71 [00:14<00:40,  1.28it/s]\u001b[A\n",
            "Iteration:  28% 20/71 [00:15<00:39,  1.28it/s]\u001b[A\n",
            "Iteration:  30% 21/71 [00:16<00:39,  1.28it/s]\u001b[A\n",
            "Iteration:  31% 22/71 [00:17<00:38,  1.27it/s]\u001b[A\n",
            "Iteration:  32% 23/71 [00:18<00:37,  1.27it/s]\u001b[A\n",
            "Iteration:  34% 24/71 [00:18<00:37,  1.27it/s]\u001b[A\n",
            "Iteration:  35% 25/71 [00:19<00:36,  1.27it/s]\u001b[A\n",
            "Iteration:  37% 26/71 [00:20<00:35,  1.27it/s]\u001b[A\n",
            "Iteration:  38% 27/71 [00:21<00:34,  1.27it/s]\u001b[A\n",
            "Iteration:  39% 28/71 [00:21<00:33,  1.27it/s]\u001b[A\n",
            "Iteration:  41% 29/71 [00:22<00:33,  1.27it/s]\u001b[A\n",
            "Iteration:  42% 30/71 [00:23<00:32,  1.27it/s]\u001b[A\n",
            "Iteration:  44% 31/71 [00:24<00:31,  1.27it/s]\u001b[A\n",
            "Iteration:  45% 32/71 [00:25<00:30,  1.27it/s]\u001b[A\n",
            "Iteration:  46% 33/71 [00:25<00:29,  1.27it/s]\u001b[A\n",
            "Iteration:  48% 34/71 [00:26<00:29,  1.26it/s]\u001b[A\n",
            "Iteration:  49% 35/71 [00:27<00:28,  1.27it/s]\u001b[A\n",
            "Iteration:  51% 36/71 [00:28<00:27,  1.27it/s]\u001b[A\n",
            "Iteration:  52% 37/71 [00:29<00:26,  1.27it/s]\u001b[A\n",
            "Iteration:  54% 38/71 [00:29<00:26,  1.27it/s]\u001b[A\n",
            "Iteration:  55% 39/71 [00:30<00:25,  1.26it/s]\u001b[A\n",
            "Iteration:  56% 40/71 [00:31<00:24,  1.26it/s]\u001b[A\n",
            "Iteration:  58% 41/71 [00:32<00:23,  1.27it/s]\u001b[A\n",
            "Iteration:  59% 42/71 [00:32<00:22,  1.27it/s]\u001b[A\n",
            "Iteration:  61% 43/71 [00:33<00:22,  1.26it/s]\u001b[A\n",
            "Iteration:  62% 44/71 [00:34<00:21,  1.26it/s]\u001b[A\n",
            "Iteration:  63% 45/71 [00:35<00:20,  1.27it/s]\u001b[A\n",
            "Iteration:  65% 46/71 [00:36<00:19,  1.27it/s]\u001b[A\n",
            "Iteration:  66% 47/71 [00:36<00:18,  1.27it/s]\u001b[A\n",
            "Iteration:  68% 48/71 [00:37<00:18,  1.26it/s]\u001b[A\n",
            "Iteration:  69% 49/71 [00:38<00:17,  1.26it/s]\u001b[A\n",
            "Iteration:  70% 50/71 [00:39<00:16,  1.27it/s]\u001b[A\n",
            "Iteration:  72% 51/71 [00:40<00:15,  1.27it/s]\u001b[A\n",
            "Iteration:  73% 52/71 [00:40<00:15,  1.26it/s]\u001b[A\n",
            "Iteration:  75% 53/71 [00:41<00:14,  1.27it/s]\u001b[A\n",
            "Iteration:  76% 54/71 [00:42<00:13,  1.26it/s]\u001b[A\n",
            "Iteration:  77% 55/71 [00:43<00:12,  1.26it/s]\u001b[A\n",
            "Iteration:  79% 56/71 [00:44<00:11,  1.26it/s]\u001b[A\n",
            "Iteration:  80% 57/71 [00:44<00:11,  1.26it/s]\u001b[A\n",
            "Iteration:  82% 58/71 [00:45<00:10,  1.26it/s]\u001b[A\n",
            "Iteration:  83% 59/71 [00:46<00:09,  1.26it/s]\u001b[A\n",
            "Iteration:  85% 60/71 [00:47<00:08,  1.25it/s]\u001b[A\n",
            "Iteration:  86% 61/71 [00:48<00:08,  1.25it/s]\u001b[A\n",
            "Iteration:  87% 62/71 [00:48<00:07,  1.25it/s]\u001b[A\n",
            "Iteration:  89% 63/71 [00:49<00:06,  1.25it/s]\u001b[A\n",
            "Iteration:  90% 64/71 [00:50<00:05,  1.26it/s]\u001b[A\n",
            "Iteration:  92% 65/71 [00:51<00:04,  1.26it/s]\u001b[A\n",
            "Iteration:  93% 66/71 [00:52<00:03,  1.26it/s]\u001b[A\n",
            "Iteration:  94% 67/71 [00:52<00:03,  1.26it/s]\u001b[A\n",
            "Iteration:  96% 68/71 [00:53<00:02,  1.26it/s]\u001b[A\n",
            "Iteration:  97% 69/71 [00:54<00:01,  1.26it/s]\u001b[A\n",
            "Iteration:  99% 70/71 [00:55<00:00,  1.25it/s]\u001b[A\n",
            "Iteration: 100% 71/71 [00:56<00:00,  1.27it/s]\n",
            "Epoch:  40% 2/5 [01:50<02:45, 55.09s/it]\n",
            "Iteration:   0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/71 [00:00<00:55,  1.26it/s]\u001b[A\n",
            "Iteration:   3% 2/71 [00:01<00:54,  1.26it/s]\u001b[A\n",
            "Iteration:   4% 3/71 [00:02<00:53,  1.26it/s]\u001b[A\n",
            "Iteration:   6% 4/71 [00:03<00:53,  1.26it/s]\u001b[A\n",
            "Iteration:   7% 5/71 [00:03<00:52,  1.25it/s]\u001b[A\n",
            "Iteration:   8% 6/71 [00:04<00:51,  1.25it/s]\u001b[A\n",
            "Iteration:  10% 7/71 [00:05<00:51,  1.25it/s]\u001b[A\n",
            "Iteration:  11% 8/71 [00:06<00:50,  1.25it/s]\u001b[A\n",
            "Iteration:  13% 9/71 [00:07<00:49,  1.25it/s]\u001b[A\n",
            "Iteration:  14% 10/71 [00:07<00:48,  1.25it/s]\u001b[A\n",
            "Iteration:  15% 11/71 [00:08<00:47,  1.25it/s]\u001b[A\n",
            "Iteration:  17% 12/71 [00:09<00:47,  1.25it/s]\u001b[A\n",
            "Iteration:  18% 13/71 [00:10<00:46,  1.25it/s]\u001b[A\n",
            "Iteration:  20% 14/71 [00:11<00:45,  1.25it/s]\u001b[A\n",
            "Iteration:  21% 15/71 [00:11<00:44,  1.25it/s]\u001b[A\n",
            "Iteration:  23% 16/71 [00:12<00:43,  1.25it/s]\u001b[A\n",
            "Iteration:  24% 17/71 [00:13<00:43,  1.25it/s]\u001b[A\n",
            "Iteration:  25% 18/71 [00:14<00:42,  1.25it/s]\u001b[A\n",
            "Iteration:  27% 19/71 [00:15<00:41,  1.24it/s]\u001b[A\n",
            "Iteration:  28% 20/71 [00:15<00:40,  1.24it/s]\u001b[A\n",
            "Iteration:  30% 21/71 [00:16<00:40,  1.25it/s]\u001b[A\n",
            "Iteration:  31% 22/71 [00:17<00:39,  1.25it/s]\u001b[A\n",
            "Iteration:  32% 23/71 [00:18<00:38,  1.24it/s]\u001b[A\n",
            "Iteration:  34% 24/71 [00:19<00:37,  1.24it/s]\u001b[A\n",
            "Iteration:  35% 25/71 [00:20<00:37,  1.24it/s]\u001b[A\n",
            "Iteration:  37% 26/71 [00:20<00:36,  1.24it/s]\u001b[A\n",
            "Iteration:  38% 27/71 [00:21<00:35,  1.24it/s]\u001b[A\n",
            "Iteration:  39% 28/71 [00:22<00:34,  1.24it/s]\u001b[A\n",
            "Iteration:  41% 29/71 [00:23<00:33,  1.24it/s]\u001b[A\n",
            "Iteration:  42% 30/71 [00:24<00:33,  1.24it/s]\u001b[A\n",
            "Iteration:  44% 31/71 [00:24<00:32,  1.24it/s]\u001b[A\n",
            "Iteration:  45% 32/71 [00:25<00:31,  1.24it/s]\u001b[A\n",
            "Iteration:  46% 33/71 [00:26<00:30,  1.24it/s]\u001b[A\n",
            "Iteration:  48% 34/71 [00:27<00:29,  1.24it/s]\u001b[A\n",
            "Iteration:  49% 35/71 [00:28<00:29,  1.24it/s]\u001b[A\n",
            "Iteration:  51% 36/71 [00:28<00:28,  1.24it/s]\u001b[A\n",
            "Iteration:  52% 37/71 [00:29<00:27,  1.24it/s]\u001b[A\n",
            "Iteration:  54% 38/71 [00:30<00:26,  1.24it/s]\u001b[A\n",
            "Iteration:  55% 39/71 [00:31<00:25,  1.24it/s]\u001b[A\n",
            "Iteration:  56% 40/71 [00:32<00:25,  1.24it/s]\u001b[A\n",
            "Iteration:  58% 41/71 [00:32<00:24,  1.24it/s]\u001b[A\n",
            "Iteration:  59% 42/71 [00:33<00:23,  1.24it/s]\u001b[A\n",
            "Iteration:  61% 43/71 [00:34<00:22,  1.24it/s]\u001b[A\n",
            "Iteration:  62% 44/71 [00:35<00:21,  1.23it/s]\u001b[A\n",
            "Iteration:  63% 45/71 [00:36<00:21,  1.24it/s]\u001b[A\n",
            "Iteration:  65% 46/71 [00:36<00:20,  1.23it/s]\u001b[A\n",
            "Iteration:  66% 47/71 [00:37<00:19,  1.23it/s]\u001b[A\n",
            "Iteration:  68% 48/71 [00:38<00:18,  1.23it/s]\u001b[A\n",
            "Iteration:  69% 49/71 [00:39<00:17,  1.23it/s]\u001b[A\n",
            "Iteration:  70% 50/71 [00:40<00:17,  1.23it/s]\u001b[A\n",
            "Iteration:  72% 51/71 [00:41<00:16,  1.23it/s]\u001b[A\n",
            "Iteration:  73% 52/71 [00:41<00:15,  1.23it/s]\u001b[A\n",
            "Iteration:  75% 53/71 [00:42<00:14,  1.23it/s]\u001b[A\n",
            "Iteration:  76% 54/71 [00:43<00:13,  1.23it/s]\u001b[A\n",
            "Iteration:  77% 55/71 [00:44<00:12,  1.23it/s]\u001b[A\n",
            "Iteration:  79% 56/71 [00:45<00:12,  1.24it/s]\u001b[A\n",
            "Iteration:  80% 57/71 [00:45<00:11,  1.24it/s]\u001b[A\n",
            "Iteration:  82% 58/71 [00:46<00:10,  1.23it/s]\u001b[A\n",
            "Iteration:  83% 59/71 [00:47<00:09,  1.23it/s]\u001b[A\n",
            "Iteration:  85% 60/71 [00:48<00:08,  1.23it/s]\u001b[A\n",
            "Iteration:  86% 61/71 [00:49<00:08,  1.23it/s]\u001b[A\n",
            "Iteration:  87% 62/71 [00:49<00:07,  1.23it/s]\u001b[A\n",
            "Iteration:  89% 63/71 [00:50<00:06,  1.22it/s]\u001b[A\n",
            "Iteration:  90% 64/71 [00:51<00:05,  1.23it/s]\u001b[A\n",
            "Iteration:  92% 65/71 [00:52<00:04,  1.23it/s]\u001b[A\n",
            "Iteration:  93% 66/71 [00:53<00:04,  1.23it/s]\u001b[A\n",
            "Iteration:  94% 67/71 [00:54<00:03,  1.22it/s]\u001b[A\n",
            "Iteration:  96% 68/71 [00:54<00:02,  1.22it/s]\u001b[A\n",
            "Iteration:  97% 69/71 [00:55<00:01,  1.23it/s]\u001b[A\n",
            "Iteration:  99% 70/71 [00:56<00:00,  1.23it/s]\u001b[A\n",
            "Iteration: 100% 71/71 [00:57<00:00,  1.24it/s]\n",
            "Epoch:  60% 3/5 [02:48<01:51, 55.76s/it]\n",
            "Iteration:   0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/71 [00:00<00:57,  1.23it/s]\u001b[A\n",
            "Iteration:   3% 2/71 [00:01<00:56,  1.23it/s]\u001b[A\n",
            "Iteration:   4% 3/71 [00:02<00:55,  1.23it/s]\u001b[A\n",
            "Iteration:   6% 4/71 [00:03<00:54,  1.23it/s]\u001b[A\n",
            "Iteration:   7% 5/71 [00:04<00:53,  1.23it/s]\u001b[A\n",
            "Iteration:   8% 6/71 [00:04<00:52,  1.23it/s]\u001b[A\n",
            "Iteration:  10% 7/71 [00:05<00:52,  1.23it/s]\u001b[A\n",
            "Iteration:  11% 8/71 [00:06<00:51,  1.23it/s]\u001b[A\n",
            "Iteration:  13% 9/71 [00:07<00:50,  1.23it/s]\u001b[A\n",
            "Iteration:  14% 10/71 [00:08<00:49,  1.23it/s]\u001b[A\n",
            "Iteration:  15% 11/71 [00:08<00:48,  1.23it/s]\u001b[A\n",
            "Iteration:  17% 12/71 [00:09<00:48,  1.23it/s]\u001b[A\n",
            "Iteration:  18% 13/71 [00:10<00:47,  1.23it/s]\u001b[A\n",
            "Iteration:  20% 14/71 [00:11<00:46,  1.23it/s]\u001b[A\n",
            "Iteration:  21% 15/71 [00:12<00:45,  1.23it/s]\u001b[A\n",
            "Iteration:  23% 16/71 [00:13<00:44,  1.23it/s]\u001b[A\n",
            "Iteration:  24% 17/71 [00:13<00:43,  1.23it/s]\u001b[A\n",
            "Iteration:  25% 18/71 [00:14<00:43,  1.23it/s]\u001b[A\n",
            "Iteration:  27% 19/71 [00:15<00:42,  1.23it/s]\u001b[A\n",
            "Iteration:  28% 20/71 [00:16<00:41,  1.23it/s]\u001b[A\n",
            "Iteration:  30% 21/71 [00:17<00:40,  1.23it/s]\u001b[A\n",
            "Iteration:  31% 22/71 [00:17<00:39,  1.23it/s]\u001b[A\n",
            "Iteration:  32% 23/71 [00:18<00:39,  1.23it/s]\u001b[A\n",
            "Iteration:  34% 24/71 [00:19<00:38,  1.23it/s]\u001b[A\n",
            "Iteration:  35% 25/71 [00:20<00:37,  1.23it/s]\u001b[A\n",
            "Iteration:  37% 26/71 [00:21<00:36,  1.23it/s]\u001b[A\n",
            "Iteration:  38% 27/71 [00:21<00:35,  1.22it/s]\u001b[A\n",
            "Iteration:  39% 28/71 [00:22<00:34,  1.23it/s]\u001b[A\n",
            "Iteration:  41% 29/71 [00:23<00:34,  1.23it/s]\u001b[A\n",
            "Iteration:  42% 30/71 [00:24<00:33,  1.23it/s]\u001b[A\n",
            "Iteration:  44% 31/71 [00:25<00:32,  1.22it/s]\u001b[A\n",
            "Iteration:  45% 32/71 [00:26<00:31,  1.23it/s]\u001b[A\n",
            "Iteration:  46% 33/71 [00:26<00:30,  1.23it/s]\u001b[A\n",
            "Iteration:  48% 34/71 [00:27<00:30,  1.22it/s]\u001b[A\n",
            "Iteration:  49% 35/71 [00:28<00:29,  1.23it/s]\u001b[A\n",
            "Iteration:  51% 36/71 [00:29<00:28,  1.23it/s]\u001b[A\n",
            "Iteration:  52% 37/71 [00:30<00:27,  1.23it/s]\u001b[A\n",
            "Iteration:  54% 38/71 [00:30<00:26,  1.23it/s]\u001b[A\n",
            "Iteration:  55% 39/71 [00:31<00:26,  1.23it/s]\u001b[A\n",
            "Iteration:  56% 40/71 [00:32<00:25,  1.23it/s]\u001b[A\n",
            "Iteration:  58% 41/71 [00:33<00:24,  1.22it/s]\u001b[A\n",
            "Iteration:  59% 42/71 [00:34<00:23,  1.22it/s]\u001b[A\n",
            "Iteration:  61% 43/71 [00:35<00:22,  1.22it/s]\u001b[A\n",
            "Iteration:  62% 44/71 [00:35<00:22,  1.22it/s]\u001b[A\n",
            "Iteration:  63% 45/71 [00:36<00:21,  1.22it/s]\u001b[A\n",
            "Iteration:  65% 46/71 [00:37<00:20,  1.22it/s]\u001b[A\n",
            "Iteration:  66% 47/71 [00:38<00:19,  1.22it/s]\u001b[A\n",
            "Iteration:  68% 48/71 [00:39<00:18,  1.22it/s]\u001b[A\n",
            "Iteration:  69% 49/71 [00:39<00:18,  1.22it/s]\u001b[A\n",
            "Iteration:  70% 50/71 [00:40<00:17,  1.22it/s]\u001b[A\n",
            "Iteration:  72% 51/71 [00:41<00:16,  1.22it/s]\u001b[A\n",
            "Iteration:  73% 52/71 [00:42<00:15,  1.22it/s]\u001b[A\n",
            "Iteration:  75% 53/71 [00:43<00:14,  1.22it/s]\u001b[A\n",
            "Iteration:  76% 54/71 [00:44<00:13,  1.22it/s]\u001b[A\n",
            "Iteration:  77% 55/71 [00:44<00:13,  1.22it/s]\u001b[A\n",
            "Iteration:  79% 56/71 [00:45<00:12,  1.22it/s]\u001b[A\n",
            "Iteration:  80% 57/71 [00:46<00:11,  1.22it/s]\u001b[A\n",
            "Iteration:  82% 58/71 [00:47<00:10,  1.22it/s]\u001b[A\n",
            "Iteration:  83% 59/71 [00:48<00:09,  1.22it/s]\u001b[A\n",
            "Iteration:  85% 60/71 [00:48<00:09,  1.21it/s]\u001b[A\n",
            "Iteration:  86% 61/71 [00:49<00:08,  1.22it/s]\u001b[A\n",
            "Iteration:  87% 62/71 [00:50<00:07,  1.22it/s]\u001b[A\n",
            "Iteration:  89% 63/71 [00:51<00:06,  1.22it/s]\u001b[A\n",
            "Iteration:  90% 64/71 [00:52<00:05,  1.22it/s]\u001b[A\n",
            "Iteration:  92% 65/71 [00:53<00:04,  1.22it/s]\u001b[A\n",
            "Iteration:  93% 66/71 [00:53<00:04,  1.22it/s]\u001b[A\n",
            "Iteration:  94% 67/71 [00:54<00:03,  1.22it/s]\u001b[A\n",
            "Iteration:  96% 68/71 [00:55<00:02,  1.22it/s]\u001b[A\n",
            "Iteration:  97% 69/71 [00:56<00:01,  1.21it/s]\u001b[A\n",
            "Iteration:  99% 70/71 [00:57<00:00,  1.21it/s]\u001b[A\n",
            "Iteration: 100% 71/71 [00:58<00:00,  1.22it/s]\n",
            "Epoch:  80% 4/5 [03:46<00:56, 56.45s/it]\n",
            "Iteration:   0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/71 [00:00<00:58,  1.20it/s]\u001b[A\n",
            "Iteration:   3% 2/71 [00:01<00:57,  1.21it/s]\u001b[A\n",
            "Iteration:   4% 3/71 [00:02<00:56,  1.21it/s]\u001b[A\n",
            "Iteration:   6% 4/71 [00:03<00:55,  1.21it/s]\u001b[A\n",
            "Iteration:   7% 5/71 [00:04<00:54,  1.22it/s]\u001b[A\n",
            "Iteration:   8% 6/71 [00:04<00:53,  1.22it/s]\u001b[A\n",
            "Iteration:  10% 7/71 [00:05<00:52,  1.22it/s]\u001b[A\n",
            "Iteration:  11% 8/71 [00:06<00:51,  1.22it/s]\u001b[A\n",
            "Iteration:  13% 9/71 [00:07<00:50,  1.22it/s]\u001b[A\n",
            "Iteration:  14% 10/71 [00:08<00:49,  1.22it/s]\u001b[A\n",
            "Iteration:  15% 11/71 [00:09<00:49,  1.22it/s]\u001b[A\n",
            "Iteration:  17% 12/71 [00:09<00:48,  1.22it/s]\u001b[A\n",
            "Iteration:  18% 13/71 [00:10<00:47,  1.22it/s]\u001b[A\n",
            "Iteration:  20% 14/71 [00:11<00:46,  1.22it/s]\u001b[A\n",
            "Iteration:  21% 15/71 [00:12<00:46,  1.22it/s]\u001b[A\n",
            "Iteration:  23% 16/71 [00:13<00:45,  1.21it/s]\u001b[A\n",
            "Iteration:  24% 17/71 [00:13<00:44,  1.21it/s]\u001b[A\n",
            "Iteration:  25% 18/71 [00:14<00:43,  1.21it/s]\u001b[A\n",
            "Iteration:  27% 19/71 [00:15<00:42,  1.21it/s]\u001b[A\n",
            "Iteration:  28% 20/71 [00:16<00:42,  1.21it/s]\u001b[A\n",
            "Iteration:  30% 21/71 [00:17<00:41,  1.22it/s]\u001b[A\n",
            "Iteration:  31% 22/71 [00:18<00:40,  1.21it/s]\u001b[A\n",
            "Iteration:  32% 23/71 [00:18<00:39,  1.21it/s]\u001b[A\n",
            "Iteration:  34% 24/71 [00:19<00:38,  1.21it/s]\u001b[A\n",
            "Iteration:  35% 25/71 [00:20<00:37,  1.21it/s]\u001b[A\n",
            "Iteration:  37% 26/71 [00:21<00:37,  1.22it/s]\u001b[A\n",
            "Iteration:  38% 27/71 [00:22<00:36,  1.21it/s]\u001b[A\n",
            "Iteration:  39% 28/71 [00:23<00:35,  1.21it/s]\u001b[A\n",
            "Iteration:  41% 29/71 [00:23<00:34,  1.21it/s]\u001b[A\n",
            "Iteration:  42% 30/71 [00:24<00:33,  1.21it/s]\u001b[A\n",
            "Iteration:  44% 31/71 [00:25<00:32,  1.22it/s]\u001b[A\n",
            "Iteration:  45% 32/71 [00:26<00:32,  1.21it/s]\u001b[A\n",
            "Iteration:  46% 33/71 [00:27<00:31,  1.21it/s]\u001b[A\n",
            "Iteration:  48% 34/71 [00:27<00:30,  1.21it/s]\u001b[A\n",
            "Iteration:  49% 35/71 [00:28<00:29,  1.21it/s]\u001b[A\n",
            "Iteration:  51% 36/71 [00:29<00:28,  1.21it/s]\u001b[A\n",
            "Iteration:  52% 37/71 [00:30<00:28,  1.21it/s]\u001b[A\n",
            "Iteration:  54% 38/71 [00:31<00:27,  1.21it/s]\u001b[A\n",
            "Iteration:  55% 39/71 [00:32<00:26,  1.21it/s]\u001b[A\n",
            "Iteration:  56% 40/71 [00:32<00:25,  1.21it/s]\u001b[A\n",
            "Iteration:  58% 41/71 [00:33<00:24,  1.21it/s]\u001b[A\n",
            "Iteration:  59% 42/71 [00:34<00:23,  1.21it/s]\u001b[A\n",
            "Iteration:  61% 43/71 [00:35<00:23,  1.21it/s]\u001b[A\n",
            "Iteration:  62% 44/71 [00:36<00:22,  1.21it/s]\u001b[A\n",
            "Iteration:  63% 45/71 [00:37<00:21,  1.21it/s]\u001b[A\n",
            "Iteration:  65% 46/71 [00:37<00:20,  1.22it/s]\u001b[A\n",
            "Iteration:  66% 47/71 [00:38<00:19,  1.21it/s]\u001b[A\n",
            "Iteration:  68% 48/71 [00:39<00:18,  1.22it/s]\u001b[A\n",
            "Iteration:  69% 49/71 [00:40<00:18,  1.22it/s]\u001b[A\n",
            "Iteration:  70% 50/71 [00:41<00:17,  1.22it/s]\u001b[A\n",
            "Iteration:  72% 51/71 [00:41<00:16,  1.21it/s]\u001b[A\n",
            "Iteration:  73% 52/71 [00:42<00:15,  1.22it/s]\u001b[A\n",
            "Iteration:  75% 53/71 [00:43<00:14,  1.21it/s]\u001b[A\n",
            "Iteration:  76% 54/71 [00:44<00:13,  1.21it/s]\u001b[A\n",
            "Iteration:  77% 55/71 [00:45<00:13,  1.22it/s]\u001b[A\n",
            "Iteration:  79% 56/71 [00:46<00:12,  1.21it/s]\u001b[A\n",
            "Iteration:  80% 57/71 [00:46<00:11,  1.21it/s]\u001b[A\n",
            "Iteration:  82% 58/71 [00:47<00:10,  1.21it/s]\u001b[A\n",
            "Iteration:  83% 59/71 [00:48<00:09,  1.21it/s]\u001b[A\n",
            "Iteration:  85% 60/71 [00:49<00:09,  1.21it/s]\u001b[A\n",
            "Iteration:  86% 61/71 [00:50<00:08,  1.21it/s]\u001b[A\n",
            "Iteration:  87% 62/71 [00:51<00:07,  1.21it/s]\u001b[A\n",
            "Iteration:  89% 63/71 [00:51<00:06,  1.21it/s]\u001b[A\n",
            "Iteration:  90% 64/71 [00:52<00:05,  1.21it/s]\u001b[A\n",
            "Iteration:  92% 65/71 [00:53<00:04,  1.21it/s]\u001b[A\n",
            "Iteration:  93% 66/71 [00:54<00:04,  1.21it/s]\u001b[A\n",
            "Iteration:  94% 67/71 [00:55<00:03,  1.21it/s]\u001b[A\n",
            "Iteration:  96% 68/71 [00:56<00:02,  1.20it/s]\u001b[A\n",
            "Iteration:  97% 69/71 [00:56<00:01,  1.21it/s]\u001b[A\n",
            "Iteration:  99% 70/71 [00:57<00:00,  1.21it/s]\u001b[A\n",
            "Iteration: 100% 71/71 [00:58<00:00,  1.21it/s]\n",
            "Epoch: 100% 5/5 [04:44<00:00, 56.92s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER9kk1YIokrm",
        "outputId": "e86e4880-a56e-46db-8792-23b188855ca2"
      },
      "source": [
        "# Evaluate for test set\n",
        "! python run_seq_labeling.py  --data_dir data \\\n",
        "                            --model_type layoutlm \\\n",
        "                            --model_name_or_path '/content/drive/My Drive/Msc/Tese/Modelos/layoutlm-base-uncased' \\\n",
        "                            --do_lower_case \\\n",
        "                            --max_seq_length 512 \\\n",
        "                            --do_predict \\\n",
        "                            --logging_steps 10 \\\n",
        "                            --save_steps -1 \\\n",
        "                            --output_dir output \\\n",
        "                            --labels data/labels.txt \\\n",
        "                            --per_gpu_eval_batch_size 8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-25 00:17:28.612540: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Evaluating: 100% 18/18 [00:04<00:00,  3.95it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qov0PELOokoN",
        "outputId": "7622f60b-e890-4eed-bfa6-7e58fe8457ba"
      },
      "source": [
        "cat output/test_results.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 = 0.945092952875054\n",
            "loss = 0.0345635545026097\n",
            "precision = 0.9138795986622074\n",
            "recall = 0.9785138764547896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK1Y0XkCoklL",
        "outputId": "ae0a9957-7cc3-4cfe-e849-847f019a1ae7"
      },
      "source": [
        "# We can check the results on the test set\n",
        "%%bash\n",
        "head -60 output/test_predictions.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UNIHAKKA B-COMPANY\n",
            "INTERNATIONAL B-COMPANY\n",
            "SDN B-COMPANY\n",
            "BHD B-COMPANY\n",
            "22 B-DATE\n",
            "JUN B-DATE\n",
            "2018 B-DATE\n",
            "18:07 O\n",
            "(867388-U) O\n",
            "12 O\n",
            "TAMPOI O\n",
            "TAX O\n",
            "INVOICE O\n",
            "INVOICE O\n",
            "# O\n",
            ": O\n",
            "OR18062202170372 O\n",
            "ITEM O\n",
            "QTY O\n",
            "TOTAL O\n",
            "SR O\n",
            "I00100000170- O\n",
            "IMPORTED O\n",
            "VEGGIES O\n",
            "RM1.50 O\n",
            "SR O\n",
            "I00100000031- O\n",
            "3 O\n",
            "VEGE O\n",
            "RM4.15 O\n",
            "SR O\n",
            "I00100000171-MEAT O\n",
            "DISH O\n",
            "RM2.83 O\n",
            "1 O\n",
            "1 O\n",
            "1 O\n",
            "RM1.50 O\n",
            "RM4.15 O\n",
            "RM2.83 O\n",
            "TOTAL O\n",
            "AMOUNT: O\n",
            "RM8.48 O\n",
            "GST O\n",
            "@0%: O\n",
            "RM0.00 O\n",
            "ROUNDING: O\n",
            "RM0.02 O\n",
            "NETT O\n",
            "TOTAL: O\n",
            "RM8.50 B-TOTAL\n",
            "PAYMENT O\n",
            "MODE O\n",
            "CASH O\n",
            "CHANGE O\n",
            "AMOUNT O\n",
            "RM8.50 B-TOTAL\n",
            "RM0.00 O\n",
            "GST O\n",
            "SUMMARY O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH69Fu_ookiA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}